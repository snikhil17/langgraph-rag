class KafkaOrchestrator(AbstractContextManager):
    consumer: Consumer

    producer: Producer

    submit: Submit

    def __init__(
        self,
        graph: Pregel,
        topics: Topics,
        batch_max_n: int = 10,
        batch_max_ms: int = 1000,
        retry_policy: Optional[RetryPolicy] = None,
        consumer: Optional[Consumer] = None,
        producer: Optional[Producer] = None,
        **kwargs: Any,
    ) -> None:
        self.graph = graph
        self.topics = topics
        self.stack = ExitStack()
        self.kwargs = kwargs
        self.consumer = consumer
        self.producer = producer
        self.batch_max_n = batch_max_n
        self.batch_max_ms = batch_max_ms
        self.retry_policy = retry_policy

    def __enter__(self) -> Self:
        self.subgraphs = dict(self.graph.get_subgraphs(recurse=True))
        self.submit = self.stack.enter_context(BackgroundExecutor({}))
        if self.consumer is None:
            from langgraph.scheduler.kafka.default_sync import DefaultConsumer

            self.consumer = self.stack.enter_context(
                DefaultConsumer(
                    self.topics.orchestrator,
                    auto_offset_reset="earliest",
                    group_id="orchestrator",
                    enable_auto_commit=False,
                    **self.kwargs,
                )
            )
        if self.producer is None:
            from langgraph.scheduler.kafka.default_sync import DefaultProducer

            self.producer = self.stack.enter_context(
                DefaultProducer(
                    **self.kwargs,
                )
            )
        return self

    def __exit__(self, *args: Any) -> None:
        return self.stack.__exit__(*args)

    def __iter__(self) -> Self:
        return self

    def __next__(self) -> list[MessageToOrchestrator]:
        # wait for next batch
        recs = self.consumer.getmany(
            timeout_ms=self.batch_max_ms, max_records=self.batch_max_n
        )
        # dedupe messages, eg. if multiple nodes finish around same time
        uniq = set(msg.value for msgs in recs.values() for msg in msgs)
        msgs: list[MessageToOrchestrator] = [serde.loads(msg) for msg in uniq]
        # process batch
        concurrent.futures.wait(self.submit(self.each, msg) for msg in msgs)
        # commit offsets
        self.consumer.commit()
        # return message
        return msgs

    def each(self, msg: MessageToOrchestrator) -> None:
        try:
            retry(self.retry_policy, self.attempt, msg)
        except CheckpointNotLatest:
            pass
        except GraphInterrupt:
            pass
        except Exception as exc:
            fut = self.producer.send(
                self.topics.error,
                value=serde.dumps(
                    ErrorMessage(
                        topic=self.topics.orchestrator,
                        msg=msg,
                        error=repr(exc),
                    )
                ),
            )
            fut.result()

    def attempt(self, msg: MessageToOrchestrator) -> None:
        # find graph
        if checkpoint_ns := msg["config"]["configurable"].get("checkpoint_ns"):
            # remove task_ids from checkpoint_ns
            recast = recast_checkpoint_ns(checkpoint_ns)
            # find the subgraph with the matching name
            if recast in self.subgraphs:
                graph = self.subgraphs[recast]
            else:
                raise ValueError(f"Subgraph {recast} not found")
        else:
            graph = self.graph
        # process message
        with SyncPregelLoop(
            msg["input"],
            config=ensure_config(msg["config"]),
            stream=None,
            store=self.graph.store,
            checkpointer=self.graph.checkpointer,
            nodes=graph.nodes,
            specs=graph.channels,
            output_keys=graph.output_channels,
            stream_keys=graph.stream_channels,
            interrupt_after=graph.interrupt_after_nodes,
            interrupt_before=graph.interrupt_before_nodes,
        ) as loop:
            if loop.tick(input_keys=graph.input_channels):
                # wait for checkpoint to be saved
                if hasattr(loop, "_put_checkpoint_fut"):
                    loop._put_checkpoint_fut.result()
                # schedule any new tasks
                if new_tasks := [
                    t for t in loop.tasks.values() if not t.scheduled and not t.writes
                ]:
                    config = patch_configurable(
                        loop.config,
                        {
                            **loop.checkpoint_config["configurable"],
                            CONFIG_KEY_DEDUPE_TASKS: True,
                            CONFIG_KEY_ENSURE_LATEST: True,
                        },
                    )
                    # send messages to executor
                    futures = [
                        self.producer.send(
                            self.topics.executor,
                            value=serde.dumps(
                                MessageToExecutor(
                                    config=config,
                                    task=ExecutorTask(id=task.id, path=task.path),
                                    finally_send=msg.get("finally_send"),
                                )
                            ),
                        )
                        for task in new_tasks
                    ]
                    # wait for messages to be sent
                    concurrent.futures.wait(futures)
                    # mark as scheduled
                    for task in new_tasks:
                        loop.put_writes(
                            task.id,
                            [
                                (
                                    SCHEDULED,
                                    max(
                                        loop.checkpoint["versions_seen"]
                                        .get(INTERRUPT, {})
                                        .values(),
                                        default=None,
                                    ),
                                )
                            ],
                        )
            elif loop.status == "done" and msg.get("finally_send"):
                # schedule any finally_send msgs
                futs = [
                    self.producer.send(
                        m["topic"],
                        value=serde.dumps(m["value"]) if m.get("value") else None,
                        key=serde.dumps(m["key"]) if m.get("key") else None,
                    )
                    for m in msg["finally_send"]
                ]
                # wait for messages to be sent
                concurrent.futures.wait(futs)