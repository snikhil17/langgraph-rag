"""Use in the conditional_edge to route to the ToolNode if the last message

has tool calls. Otherwise, route to the end.

Args:
    state (Union[list[AnyMessage], dict[str, Any], BaseModel]): The state to check for
        tool calls. Must have a list of messages (MessageGraph) or have the
        "messages" key (StateGraph).

Returns:
    The next node to route to.


Examples:
    Create a custom ReAct-style agent with tools.

    ```pycon
    >>> from langchain_anthropic import ChatAnthropic
    >>> from langchain_core.tools import tool
    ...
    >>> from langgraph.graph import StateGraph
    >>> from langgraph.prebuilt import ToolNode, tools_condition
    >>> from langgraph.graph.message import add_messages
    ...
    >>> from typing import Annotated
    >>> from typing_extensions import TypedDict
    ...
    >>> @tool
    >>> def divide(a: float, b: float) -> int:
    ...     """Return a / b."""
    ...     return a / b
    ...
    >>> llm = ChatAnthropic(model="claude-3-haiku-20240307")
    >>> tools = [divide]
    ...
    >>> class State(TypedDict):
    ...     messages: Annotated[list, add_messages]
    >>>
    >>> graph_builder = StateGraph(State)
    >>> graph_builder.add_node("tools", ToolNode(tools))
    >>> graph_builder.add_node("chatbot", lambda state: {"messages":llm.bind_tools(tools).invoke(state['messages'])})
    >>> graph_builder.add_edge("tools", "chatbot")
    >>> graph_builder.add_conditional_edges(
    ...     "chatbot", tools_condition
    ... )
    >>> graph_builder.set_entry_point("chatbot")
    >>> graph = graph_builder.compile()
    >>> graph.invoke({"messages": {"role": "user", "content": "What's 329993 divided by 13662?"}})
    ```"""
def tools_condition(
    state: Union[list[AnyMessage], dict[str, Any], BaseModel],
    messages_key: str = "messages",
) -> Literal["tools", "__end__"]:
    """Use in the conditional_edge to route to the ToolNode if the last message

    has tool calls. Otherwise, route to the end.

    Args:
        state (Union[list[AnyMessage], dict[str, Any], BaseModel]): The state to check for
            tool calls. Must have a list of messages (MessageGraph) or have the
            "messages" key (StateGraph).

    Returns:
        The next node to route to.


    Examples:
        Create a custom ReAct-style agent with tools.

        ```pycon
        >>> from langchain_anthropic import ChatAnthropic
        >>> from langchain_core.tools import tool
        ...
        >>> from langgraph.graph import StateGraph
        >>> from langgraph.prebuilt import ToolNode, tools_condition
        >>> from langgraph.graph.message import add_messages
        ...
        >>> from typing import Annotated
        >>> from typing_extensions import TypedDict
        ...
        >>> @tool
        >>> def divide(a: float, b: float) -> int:
        ...     \"\"\"Return a / b.\"\"\"
        ...     return a / b
        ...
        >>> llm = ChatAnthropic(model="claude-3-haiku-20240307")
        >>> tools = [divide]
        ...
        >>> class State(TypedDict):
        ...     messages: Annotated[list, add_messages]
        >>>
        >>> graph_builder = StateGraph(State)
        >>> graph_builder.add_node("tools", ToolNode(tools))
        >>> graph_builder.add_node("chatbot", lambda state: {"messages":llm.bind_tools(tools).invoke(state['messages'])})
        >>> graph_builder.add_edge("tools", "chatbot")
        >>> graph_builder.add_conditional_edges(
        ...     "chatbot", tools_condition
        ... )
        >>> graph_builder.set_entry_point("chatbot")
        >>> graph = graph_builder.compile()
        >>> graph.invoke({"messages": {"role": "user", "content": "What's 329993 divided by 13662?"}})
        ```
    """
    if isinstance(state, list):
        ai_message = state[-1]
    elif isinstance(state, dict) and (messages := state.get(messages_key, [])):
        ai_message = messages[-1]
    elif messages := getattr(state, messages_key, []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"No messages found in input state to tool_edge: {state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return "__end__"